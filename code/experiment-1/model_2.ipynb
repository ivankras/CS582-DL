{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Mini Project 2 - DL Skills - Modeling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import libraries and load data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from utils import (\n",
    "    get_category,\n",
    "    get_prepared_data\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "(x_train, x_test), (y_train, y_test) = get_prepared_data()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "batch_size = 16\n",
    "\n",
    "# https://www.tensorflow.org/tutorials/load_data/numpy\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(50000, reshuffle_each_iteration=True)\n",
    "train_dataset = train_dataset.batch(batch_size, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_dataset = train_dataset.repeat(4)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_dataset = test_dataset.shuffle(10000, reshuffle_each_iteration=True)\n",
    "test_dataset = test_dataset.batch(batch_size, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.repeat(4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Network"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model: VGG"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from model_utils import get_vgg\n",
    "\n",
    "model = get_vgg()\n",
    "\n",
    "model.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from keras.optimizers import adam_v2\n",
    "\n",
    "opt = adam_v2.Adam(\n",
    "    learning_rate=0.001,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07,\n",
    "    amsgrad=True\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss=keras.losses.categorical_crossentropy,\n",
    "    metrics=['accuracy']\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from keras.callbacks import (ModelCheckpoint, EarlyStopping)\n",
    "checkpoint = ModelCheckpoint(\n",
    "    \"updated_vgg.h5\",\n",
    "    monitor='val_acc',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='auto',\n",
    "    save_freq='epoch'\n",
    ")\n",
    "early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=20, verbose=1, mode='auto')\n",
    "hist = model.fit(\n",
    "    x=train_dataset,\n",
    "    steps_per_epoch=100,\n",
    "    validation_data=test_dataset,\n",
    "    validation_steps=10,\n",
    "    epochs=100,\n",
    "    callbacks=[checkpoint, early]\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot Learning Curves (Loss and Accuracy)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "\n",
    "ax1.plot(hist.history[\"loss\"])\n",
    "ax1.plot(hist.history[\"val_loss\"])\n",
    "ax1.set_title(\"model loss\")\n",
    "ax1.set_ylabel(\"loss\")\n",
    "ax1.set_xlabel(\"epoch\")\n",
    "ax1.legend([\"train\", \"test\"], loc=\"upper left\")\n",
    "\n",
    "ax2.plot(hist.history[\"accuracy\"])\n",
    "ax2.plot(hist.history[\"val_accuracy\"])\n",
    "ax2.set_title(\"model accuracy\")\n",
    "ax2.set_ylabel(\"accuracy\")\n",
    "ax2.set_xlabel(\"epoch\")\n",
    "ax2.legend([\"train\", \"test\"], loc=\"upper left\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Predictions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Array predictions\n",
    "y_hat = model.predict(x_test)\n",
    "\n",
    "# Single prediction\n",
    "# y_hat_2000 = model.predict(x_test[2000])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Recheck accuracy calculation on test set\n",
    "count = 0\n",
    "for i in range(len(y_test)):\n",
    "    if np.argmax(y_test[i]) == np.argmax(y_hat[i]):\n",
    "        count += 1\n",
    "print(f'Matches: {count} out of {len(y_test)}')\n",
    "\n",
    "# Single prediction\n",
    "# print(get_category(y_test[2000], verbose=True))\n",
    "# print(get_category(y_hat_2000, verbose=True))\n",
    "\n",
    "# Array predictions\n",
    "test_idx = 30\n",
    "print(get_category(y_test[test_idx], verbose=True))\n",
    "print(get_category(y_hat[test_idx], verbose=True))\n",
    "Image.fromarray((x_test[test_idx] * 255.0).reshape(32, 32)).convert('L').resize((128, 128))"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('venv': venv)"
  },
  "interpreter": {
   "hash": "ca2a4fbeb6acb7be4e9ed99c6d95e320cf98efc94edc513072d2e669539c4e38"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}