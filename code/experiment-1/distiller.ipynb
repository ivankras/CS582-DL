{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Mini Project 2 - DL Skills - Distiller"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import libraries and load data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from utils import get_prepared_data\n",
    "from model_utils import (\n",
    "    get_student_vgg,\n",
    "    get_vgg\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create the teacher\n",
    "teacher = get_vgg()\n",
    "\n",
    "# Create the student\n",
    "student = get_student_vgg()\n",
    "\n",
    "# Clone student for later comparison\n",
    "student_scratch = keras.models.clone_model(student)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "(x_train, x_test), (y_train, y_test) = get_prepared_data()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "batch_size = 8\n",
    "\n",
    "# https://www.tensorflow.org/tutorials/load_data/numpy\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.repeat(8)\n",
    "train_dataset = train_dataset.shuffle(400000, reshuffle_each_iteration=True)\n",
    "train_dataset = train_dataset.batch(batch_size, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_dataset = test_dataset.repeat(8)\n",
    "test_dataset = test_dataset.shuffle(80000, reshuffle_each_iteration=True)\n",
    "test_dataset = test_dataset.batch(batch_size, num_parallel_calls=tf.data.AUTOTUNE)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compile and train teacher model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from keras.optimizers import adam_v2\n",
    "\n",
    "opt = adam_v2.Adam(\n",
    "    learning_rate=0.001,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07,\n",
    "    amsgrad=True\n",
    ")\n",
    "\n",
    "teacher.compile(\n",
    "    optimizer=opt,\n",
    "    loss=keras.losses.categorical_crossentropy,\n",
    "    metrics=['accuracy']\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from keras.callbacks import (ModelCheckpoint, EarlyStopping)\n",
    "\n",
    "teacher_hist = teacher.fit(\n",
    "    x=train_dataset,\n",
    "    steps_per_epoch=100,\n",
    "    validation_data=test_dataset,\n",
    "    validation_steps=10,\n",
    "    epochs=200\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compile and fit student"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from model_utils import Distiller\n",
    "\n",
    "# Initialize and compile distiller\n",
    "distiller = Distiller(student=student, teacher=teacher)\n",
    "distiller.compile(\n",
    "    optimizer=opt,\n",
    "    metrics=['accuracy'],\n",
    "    student_loss_fn=keras.losses.categorical_crossentropy,\n",
    "    distillation_loss_fn=keras.losses.KLDivergence(),\n",
    "    alpha=0.1,\n",
    "    temperature=30\n",
    ")\n",
    "\n",
    "# Distill teacher to student\n",
    "dist_hist = distiller.fit(\n",
    "    x=train_dataset,\n",
    "    steps_per_epoch=100,\n",
    "    validation_data=test_dataset,\n",
    "    validation_steps=10,\n",
    "    epochs=100\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Train student as doen usually\n",
    "student_scratch.compile(\n",
    "    optimizer=opt,\n",
    "    loss=keras.losses.categorical_crossentropy,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train and evaluate student trained from scratch.\n",
    "st_hist = student_scratch.fit(\n",
    "    x=train_dataset,\n",
    "    steps_per_epoch=100,\n",
    "    validation_data=test_dataset,\n",
    "    validation_steps=10,\n",
    "    epochs=100\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot Learning Curves (Loss and Accuracy)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(12, 12))\n",
    "min_y, max_y = 0.1, 0.85\n",
    "\n",
    "# Teacher\n",
    "\n",
    "ax4.plot(teacher_hist.history[\"loss\"])\n",
    "ax4.plot(teacher_hist.history[\"val_loss\"])\n",
    "ax4.set_title(\"teacher loss\")\n",
    "ax4.set_ylabel(\"loss\")\n",
    "ax4.set_xlabel(\"epoch\")\n",
    "ax4.legend([\"train\", \"test\"], loc=\"upper left\")\n",
    "\n",
    "ax1.plot(teacher_hist.history[\"accuracy\"])\n",
    "ax1.plot(teacher_hist.history[\"val_accuracy\"])\n",
    "ax1.set_title(\"teacher accuracy\")\n",
    "ax1.set_ylabel(\"accuracy\")\n",
    "ax1.set_xlabel(\"epoch\")\n",
    "ax1.legend([\"train\", \"test\"], loc=\"upper left\")\n",
    "ax1.set_ylim([min_y, max_y])\n",
    "\n",
    "# Distilled\n",
    "\n",
    "ax2.plot(dist_hist.history[\"accuracy\"])\n",
    "ax2.plot(dist_hist.history[\"val_accuracy\"])\n",
    "ax2.set_title(\"student distilled accuracy\")\n",
    "ax2.set_ylabel(\"accuracy\")\n",
    "ax2.set_xlabel(\"epoch\")\n",
    "ax2.legend([\"train\", \"test\"], loc=\"upper left\")\n",
    "ax2.set_ylim([min_y, max_y])\n",
    "\n",
    "# Student scratch\n",
    "\n",
    "ax3.plot(st_hist.history[\"accuracy\"])\n",
    "ax3.plot(st_hist.history[\"val_accuracy\"])\n",
    "ax3.set_title(\"student not distilled accuracy\")\n",
    "ax3.set_ylabel(\"accuracy\")\n",
    "ax3.set_xlabel(\"epoch\")\n",
    "ax3.legend([\"train\", \"test\"], loc=\"upper left\")\n",
    "ax3.set_ylim([min_y, max_y])\n",
    "\n",
    "ax5.set_visible(False)\n",
    "ax6.set_visible(False)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('venv': venv)"
  },
  "interpreter": {
   "hash": "ca2a4fbeb6acb7be4e9ed99c6d95e320cf98efc94edc513072d2e669539c4e38"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}